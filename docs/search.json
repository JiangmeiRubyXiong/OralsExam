[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Orals",
    "section": "",
    "text": "Statistical Analysis in Multiplexed Immunofluorescence Imaging\nThis is the document for doctoral oral exam of Jiangmei Xiong. The topic of this oral exam is data preprocessing of mIF imaging data. This document will walk you through the basics of multiplexed immunofluorescence image, Jiangmei’s first dissertation paper, and a literature review for missing data imputation in multiplexed immunofluorescence imaging."
  },
  {
    "objectID": "Introduction to mIF.html#multiplexed-immunofluorescence-images",
    "href": "Introduction to mIF.html#multiplexed-immunofluorescence-images",
    "title": "1  Chapter 1: Introduction to Multiplexed Immunofluorescence Images",
    "section": "1.1 Multiplexed Immunofluorescence Images",
    "text": "1.1 Multiplexed Immunofluorescence Images\nMultiplexed Immunofluorescence (mIF) Image is a recent development from Immunofluorescence (IF), a branch of Immunohistochemistry (IHC). The first structural conceptualization of IHC is established in 1941. Coons, Creech, and Jones (1941) described that in formalin-prefixed mammalian tissue, there is a type of antibody that can be identified by fluorescent antigens. Since then, IHC is developed into an important tool for cancer diagnosis (Duraiyan et al. 2012). Within the word “immunohistochemistry”, “immuno” refers to the antigen-antibody reaction in the process, “histo” means tissue, and “chemistry” is the process. During IHC, antibody can be tagged with labels such as enzyme, fluorochromes, which reacts when the corresponding antigen-antibody bind is formed (Ramos-Vara 2005). Similarly, the word immunofluorescence can split into “immuno” and “fluorescence”, and “fluorescence” corresponds to the fluorescent signal generated by the fluorocromes(Hussaini, Seo, and Rich 2022).\nIHC/IF can only detect one biomarker for a tissue region. This limitation makes IHC/IF unable to identify more complicated expression patterns that require more than one biomarker (Sheng et al. 2023). The development of multiplexed IHC (mIHC)/IF(mIF) image resolved this issue. Multiplexed IHC/IF image display different protein information for each plex of the image, while retaining the spatial and morphological information of the tissue (Eng et al. 2022). mIHC/mIF can be seen as a stack of images, each presenting a different portion of the same tissue.\n\n\n\nFigure 1.1: This is what it might look like if Waldo is to be analyzed in mIF style (?Maybe?).\n\n\nFigure 1.2 by Sheng et al. (2023) shows several different methods for creating mIF images. It can be seen that the first two methods both uses cycles of stain-photo-removal, and the last method is a one-off step where all labels are tagged at once. Sheng et al. (2023) also tabulated all multiplexd IHC/IF technologies, where the number of biomarkers that can be identified ranges from 4 to 100.\n\n\n\n\nFigure 1.2: Different methods for creating mIF/mIHC images. Image courtesy of Sheng et al. (2023)\n\n\n\nmIHC/mIF images are widely used in studies for immune tumor microenvironments (iTME). The studies often involves cell type proportions within a certain region, spatial clustering of immune cells or spatial interaction among different cell types (Wrobel, Harris, and Vandekar 2023). For example: Schürch et al. (2020) discovered that within granulcyte cell meightborhood, the enrichment PD-1+CD4+ T cells are correlated with the survival outcome of a subset of colorectal cancer patients; Chen et al. (2021) shows different immune cell proportion and clustering between different colorectal tumor types; Steinhart et al. (2021) found that certain immune cell proportions and spatial interactions are correlated with ovarian cancer patient survival outcomes."
  },
  {
    "objectID": "Introduction to mIF.html#data-structure",
    "href": "Introduction to mIF.html#data-structure",
    "title": "1  Chapter 1: Introduction to Multiplexed Immunofluorescence Images",
    "section": "1.2 Data Structure",
    "text": "1.2 Data Structure\nFor mIHC/mIF images, each individual “plex” corresponds to a different immune protein identified by a type of stain. Each plex goes through analogous transition as shown in Figure 1.3 and form a table of cell expressions, and the tables of different protein expressions are combined in the end.\nInitially, greyscale intensity is assigned to each pixel. The greyscale intensity is taken as the intensity of marker expression. The image then goes through cell segmentation, which are usually based on machine learning or deep learning methods(McKinley et al. 2022; Schüffler et al. 2015). DAPI, a fluorescent stain typically used for cell morphology identification, is most often used for the initial cell segmentation. The same cell-segmentation will be used for all other marker channels. Next, the pixel intensities, pixel positions, and the cell that the pixel belongs to are entered into a dataframe. Finally, the pixel intensities and position will be averaged within the cell group. Often, the median of pixel intensities is used as well, to reduce the impact of pixel intensity outliers. The end result after combining all marker channels will be a dataset with each row representing an individual cell, columns of different marker expressions, and cell properties such as position, cell type (e.g. tumor cell or not, tissue type).\n\n\n\nFigure 1.3: Transition from a single-plex mIHC/mIF image to a single-cell dataframe. The greyscale intensity range is only a demonstration. In application, the range of the greyscale intensity depends on the configuration of image softwares. The cell intensity of the bottom left cell is shown in the table as an example.\n\n\n\n\n\n\nChen, Bob, Scurrah Cherie’R, Eliot T McKinley, Alan J Simmons, Marisol A Ramirez-Solano, Xiangzhu Zhu, Nicholas O Markham, et al. 2021. “Differential Pre-Malignant Programs and Microenvironment Chart Distinct Paths to Malignancy in Human Colorectal Polyps.” Cell 184 (26): 6262–80.\n\n\nCoons, Albert H, Hugh J Creech, and R Norman Jones. 1941. “Immunological Properties of an Antibody Containing a Fluorescent Group.” Proceedings of the Society for Experimental Biology and Medicine 47 (2): 200–202.\n\n\nDuraiyan, Jeyapradha, Rajeshwar Govindarajan, Karunakaran Kaliyappan, and Murugesan Palanisamy. 2012. “Applications of Immunohistochemistry.” Journal of Pharmacy & Bioallied Sciences 4 (Suppl 2): S307.\n\n\nEng, Jennifer, Elmar Bucher, Zhi Hu, Ting Zheng, Summer L Gibbs, Koei Chin, and Joe W Gray. 2022. “A Framework for Multiplex Imaging Optimization and Reproducible Analysis.” Communications Biology 5 (1): 438.\n\n\nHussaini, Haizal Mohd, Benedict Seo, and Alison M Rich. 2022. “Immunohistochemistry and Immunofluorescence.” In Oral Biology: Molecular Techniques and Applications, 439–50. Springer.\n\n\nMcKinley, Eliot T, Justin Shao, Samuel T Ellis, Cody N Heiser, Joseph T Roland, Mary C Macedonia, Paige N Vega, Susie Shin, Robert J Coffey, and Ken S Lau. 2022. “MIRIAM: A Machine and Deep Learning Single-Cell Segmentation and Quantification Pipeline for Multi-Dimensional Tissue Images.” Cytometry Part A 101 (6): 521–28.\n\n\nRamos-Vara, Jose A. 2005. “Technical Aspects of Immunohistochemistry.” Veterinary Pathology 42 (4): 405–26.\n\n\nSchüffler, Peter J, Denis Schapiro, Charlotte Giesen, Hao AO Wang, Bernd Bodenmiller, and Joachim M Buhmann. 2015. “Automatic Single Cell Segmentation on Highly Multiplexed Tissue Images.” Cytometry Part A 87 (10): 936–42.\n\n\nSchürch, Christian M, Salil S Bhate, Graham L Barlow, Darci J Phillips, Luca Noti, Inti Zlobec, Pauline Chu, et al. 2020. “Coordinated Cellular Neighborhoods Orchestrate Antitumoral Immunity at the Colorectal Cancer Invasive Front.” Cell 182 (5): 1341–59.\n\n\nSheng, Wenjie, Chaoyu Zhang, TM Mohiuddin, Marwah Al-Rawe, Felix Zeppernick, Franco H Falcone, Ivo Meinhold-Heerlein, and Ahmad Fawzi Hussain. 2023. “Multiplex Immunofluorescence: A Powerful Tool in Cancer Immunotherapy.” International Journal of Molecular Sciences 24 (4): 3086.\n\n\nSteinhart, Benjamin, Kimberly R Jordan, Jaidev Bapat, Miriam D Post, Lindsay W Brubaker, Benjamin G Bitler, and Julia Wrobel. 2021. “The Spatial Context of Tumor-Infiltrating Immune Cells Associates with Improved Ovarian Cancer Survival.” Molecular Cancer Research 19 (12): 1973–79.\n\n\nWrobel, Julia, Coleman Harris, and Simon Vandekar. 2023. “Statistical Analysis of Multiplex Immunofluorescence and Immunohistochemistry Imaging Data.” In Statistical Genomics, 141–68. Springer."
  },
  {
    "objectID": "GammaGateR.html#research-question",
    "href": "GammaGateR.html#research-question",
    "title": "2  Chapter 2: GammaGateR",
    "section": "2.1 Research question",
    "text": "2.1 Research question\nBefore important spatial insights can be gleaned using statistical methods, mIF images undergo an intensive preprocessing pipeline to obtain single-cell measurements. While there are various steps included in the pipeline such as image registration, single-cell segmentation, quantification, and batch correction, cell phenotyping is typically the final step before downstream analyses on the cell-level data (Graf et al. 2022; Harris et al. 2022). Cell phenotyping identifies individual cell phenotypes from the measured marker expression values of the cell and directly affects the subsequent cell population analysis results.\nThe two most common approaches for cell phenotyping in mIF are manual gating and graph-based multivariate clustering. In manual gating, each sample is visualized separately to determine a threshold, and super-threshold cells are labeled as marker positive. This procedure is repeated for all marker channels and slides, and the phenotypes are determined by combining combinations of marker-positive cells (Chen et al. 2021; Lin et al. 2023). An example for cell phenotyping from gated markers is presented in Table 2.1. Alternatively, multivariate graph-based clustering is adapted from other single-cell assays. This approach first performs cell clustering, then assigns a phenotype to each cell group based on their average expression profile. Multivariate graph-based clustering is implemented with various modifications across many software packages. Unfortunately, both methods are labor intensive, and their accuracy suffers from image noise and spatial artifacts in mIF images that cause marker expression histograms to appear continuous or uni-modal . As a result, both phenotyping methods possess shortcomings that cannot be ignored. On one hand, manual gating can be subjective. On the other hand, graph-based clustering results are prone to over-clustering and producing poor separation between clusters.\n\n\nTable 2.1: The table on the left shows that cells with positive expression of marker CD19 should be classified as B cell, and cell with positive CK expression should be classified as Tumore cell. The table on the right is a hypothetical table of cell marker expression and cell type classification based on it.\n\n\n\n\n(a) Cell type and marker correspondence\n\n\nCell Types\nMarkers\n\n\n\n\nB cells\nCD19+\n\n\nTumor\nCK+\n\n\n\n\n\n\n(b) Example of cell phenotyping based on marker expression.\n\n\nCell ID\nCD19+\nCK+\nTumor\nB cells\n\n\n\n\n1\nTRUE\nTRUE\nTRUE\nTRUE\n\n\n2\nTRUE\nFALSE\nTRUE\nFALSE\n\n\n3\nFALSE\nFALSE\nFALSE\nFALSE"
  },
  {
    "objectID": "GammaGateR.html#previous-works",
    "href": "GammaGateR.html#previous-works",
    "title": "2  Chapter 2: GammaGateR",
    "section": "2.2 Previous works",
    "text": "2.2 Previous works\nThe challenges described above are well recognized and there are a few methods and software developed that attempt to automate cell phenotyping for mIF images. For example, CellSighter is a recently proposed supervised deep-learning algorithm for cell phenotyping that requires a “gold standard” training dataset (Amitay et al. 2023). Another recent solution, ASTIR (Automated assignment of cell identity from single-cell multiplexed imaging and proteomic data), is a fast unsupervised approach that defines cell phenotypes from segmented cell-level data by using a neural network-based mixture model assuming a multivariate log-normal distribution (Geuenich et al. 2021). Instead of binary outputs like in classification methods, ASTIR returns posterior probabilities of different cell types for each cell. This type of output is advantageous because it offers more information than nominal cell types and leaves cell labeling to the clinician’s discretion. Lastly, (Ahmadian et al. 2022) treat the analysis as a pixel classification problem and design a single-step framework for mIF phenotyping that is integrated with other preprocessing steps.\nNevertheless, inconsistencies persist in the results rendered by these learning-based methods when applied across markers, slides, batches, and datasets. These inconsistencies result from the immense variation in the cell-level distribution of phenotyping markers that are often too nuanced to be removed by existing batch correction methods (Wilson et al. 2021; Hunt et al. 2022). For these reasons, it is difficult to fully automate the cell phenotyping process, despite the availability of automated tools, and manual gating is still used to perform cell phenotyping because it is easy to visualize and evaluate the quality of the phenotype."
  },
  {
    "objectID": "GammaGateR.html#methods",
    "href": "GammaGateR.html#methods",
    "title": "2  Chapter 2: GammaGateR",
    "section": "2.3 Methods",
    "text": "2.3 Methods\nSince automated methods cannot be run without evaluation and supervised methods require a gold-standard dataset, no method is truly fully automated. As a solution, we develop an explicitly semi-automated algorithm called GammaGateR. GammaGateR allows the user to easily perform cell phenotyping, visualize results, and conduct interpretable quality control while reducing manual labor. Based on a novel closed-form Gamma mixture model (cfGMM), GammaGateR is a probabilistic model that is fitted to each channel and slide separately, and outputs positive-component probabilities for each marker. These can then be easily thresholded and combined for semi-automated marker gating or input directly into downstream analysis. GammaGateR has important technical advantages, including 1) improved computation time and model convergence due to its novel closed-form property, and 2) high consistency and reproducibility for phenotyping results across mIF data batches due to incorporation of parameter boundary constraints. In applications on real-world mIF data, we find that GammaGateR has fast and consistent results across many slides and markers. We provide an open-source implementation of our method in the new GammaGateR R package.\n\n2.3.1 GammaGateR\nThe GammaGateR algorithm is unique to existing methods for its focus on parsimoniously modeling cell-level marker expression densities. This approach yields tailored-to-slide model estimation in cell-level mIF data where marker expression distributions can vary substantially across slides. The algorithm uses a zero-inflated two-component GMM to model marker expression for each slide. The Gamma mixture model naturally identifies marker-positive and marker-negative cell distributions and returns the probability of belonging to the marker-positive cell distribution for each cell. The returned probabilities can either be used directly in subsequent analysis or combined and dichotomized to define cell phenotypes. GammaGateR incorporates user-specified constraints to provide consistent model fit across a large number of slides. The model evaluation methods included in GammaGateR allow the user to evaluate the constraints and quality check results. The power source of GammaGateR is the closed-form Gamma mixture model, which is a novel approach to phenotyping for mIF data that makes it more computationally efficient than traditional GMMs.\nThe analysis pipeline is illustrated for the CD4 marker channel (Figure 2.1). GammaGateR takes a single-cell image dataset, with each row corresponding to an individual cell, and each column as the normalized intensity of a marker channel for each cell (Figure 2.1 1). The first step is selecting biological constraints for model fitting by visualizing overlay histograms for each marker channel (Figure 2.1 2). The constraints are not manual thresholds, but represent boundaries for the mode of each component of the fitted distribution across all slides in the dataset. Because marker-positive cells often are a small proportion of all cells and have higher expression values, we limit the mode of the higher component to be no lower than the “elbow” of the overlay histograms (Figure 2.1 2, e.g. 0.45). While GammaGateR can be fit without constraints, the constraints provide more consistent model estimation across many slides. Given the data and constraints, GammaGateR generates the parameter estimates of the Gamma mixture model including modes and proportion of each component, and the posterior and marginal probabilities of each cell being marker-positive.\nTo ensure accurate model fitting, GammaGateR includes functionality for users to evaluate model fit and modify the fit when needed. Diagnostic plots for the fitted GammaGateR model object consist of a scatter plot of all the slides fitted model modes and lambda (marker-positive probability), and the fitted density curve over the cell expression histogram for each slide in the data set (Figure 2.1 5.a). The x-axis of the scatter plot is the mode for the marker-positive component, and the y-axis is the proportion of the corresponding component. The scatter plot is useful for identifying slides that are outliers with respect to where the mode of marker-positive cells lies or the estimated proportion of marker-positive cells. The histograms can be used for visually evaluating model fit for one slide. A good model fit shows an approximate fit of the smooth density line to the histogram with a marker-positive cell distribution sitting to the right (Figure 2.1 5.a). If there is poor model fit, users can compare fitted models between two different constraints to check how different boundaries affect fitted values (Figure 2.1 5.b). Figure 2.1 5.b compares the model fit for CD4 with no constraints (green) to the model fit with an initial constraint with a lower bound of 0.45 for the marker-positive component (red). The model without constraints places the marker-positive distribution directly over the marker-negative distribution. Users can adjust the parameter boundaries and fit again until satisfactory fittings are rendered. Finally, the output of the fitted models is easily accessible in the GammaGateR model object (Figure 2.1 6). The vignette in the GammaGateR R package provides a guide to fitting the GammaGateR model in the lung cancer dataset from the VectraPolaris dataset available on Bioconductor.\n\n\n\n\nFigure 2.1: Overview of GammaGateR analysis pipeline for the CD4 marker channel. (1) GammaGateR takes segmented cell-level data as input. (2) Density polygons are used to visualize all slide level histograms and select constraints for model fit (3). (4) After model estimation, (5.a) diagnostic plots are used to evaluate the model fit. (5.b) New constraints can be selected and the refitted model can be compared to a previous model. (6) Expression probabilities can be extracted for downstream analysis from the model objects.\n\n\n\nIn the extreme tails, the marker-positive probability might not always be higher than that of marker-negative, due to different variances of the two components’ Gamma distributions. Therefore, we apply a correction to the posterior probabilities to force them to be monotonic with respect to the marker values. Specifically, after the first crossing of the density curves of the two components, the density curve of the first component will be forced to be non-increasing, and the density curve of the second component will be forced to be non-decreasing. In addition to the posterior probability, GammaGateR also outputs the marginal probability of the observed marker value for the marker-positive component. The marginal probability is monotonically increasing in the marker intensities and represents the probability that a marker positive cell is less than the given value, x.\n\n\n2.3.2 cfGMM\nFor mIF data, we use the GMM to fit cell marker expression values as a weighted sum of different probability distributions that represent unique cell populations (McLachlan, Lee, and Rathnayake 2019). The Gamma distribution is an excellent model for marker values because the domain of the Gamma distribution is strictly positive and it has the flexibility to model the varying skewed densities seen in mIF marker values (Figure 2.1 5.a). However, GMMs are not scalable for mIF image data, because they rely on computationally inefficient numerical methods to obtain the maximum likelihood estimator (MLE). The slow convergence of the MLE for the GMM makes it prohibitive to apply across a large number of channels, slides, and cells. As a solution, we develop a closed-form GMM (cfGMM) estimation procedure based on a recently developed estimator for the Gamma distribution (Ye and Chen 2017). In addition, to improve computational efficiency, the cfGMM has the benefit of allowing prior constraints on model parameters. With the cfGMM in GammaGateR, we enable the flexibility to include a biologically meaningful range for the mode of each component in the Gamma mixture model. This way, users of GammaGateR can restrict estimation to biologically meaningful values.\n\n2.3.2.1 Derivation\nWe assume the data is a random sample x1,…,xnx_1, \\ldots, x_n from a KK component generalized gamma mixture distribution. The density function of XX is P(X=x)=∑k=1Kλkf(x;ak,bk,γk).\\begin{equation*}\nP(X=x)=\\sum_{k=1}^K \\lambda_k f(x; a_k, b_k, \\gamma_k).\n\\end{equation*} and the log-likelihood of the dataset is ℓ(𝐱|𝐚,𝐛,𝛌)=∑i=1nlog{∑k=1Kλkf(xi|ak,bk)}\\begin{equation}\n    \\ell(\\mathbf{x}|\\mathbf{a},\\mathbf{b},\\pmb{\\lambda})=\\sum^n_{i=1}\\log\\left\\{\\sum^K_{k=1}\\lambda_kf(x_i|a_k,b_k)\\right\\}\n    \\label{eq:loglikelihood}\n\\end{equation} For each generalized gamma component kk, λk∈[0,1]\\lambda_k\\in [0,1] are the mixture parameters, ∑kλk=1\\sum_{k} \\lambda_k = 1; ff denotes the generalized gamma density function; ak,bk,γka_k, b_k, \\gamma_k are the parameters for the generalized gamma.\nHere, we use the expectation maximization (EM) algorithm [dempster_maximum_1977] for parameter estimation. EM algorithm is a standard approach for parameter estimation in mixture models. It introduces the latent multinomial variable Zi=(Zi1,…,ZiK)Z_{i} = (Z_{i1}, \\ldots, Z_{iK}) into the model and maximizes the expected value of the complete data likelihood [dempster_maximum_1977]. The expectation of the complete data likelihood to be maximized for the generalized gamma distribution is 𝔼Zℓ(x∣Z)=∑i=1n∑k=1Kziklogf(xi;ak,bk,γk),\\begin{equation*}\n\\mathbb{E}_Z \\ell(x \\mid Z) = \\sum_{i=1}^n \\sum_{k=1}^K z_{ik} \\log f(x_i; a_k, b_k,\\gamma_k),\n\\end{equation*} where zik=ℙ(Zik=1∣xi;𝐚,𝐛,𝛄)=f(xi|ak,bk,γk)∑j=1Kf(xi|aj,bj,γk),\\begin{equation}\n \\label{eq:lambdaFormula}\n    z_{ik} = \\mathbb{P}(Z_{ik}=1 \\mid x_i;\\pmb{ a, b, \\gamma} ) =\\frac{f(x_i|a_k, b_k, \\gamma_k)}{\\displaystyle\\sum^K_{j=1}f(x_i|a_j, b_j, \\gamma_k)},\n \\end{equation} 𝐚=(a1,a2,…,aK)\\mathbf{a} = (a_1, a_2, \\ldots, a_K), and 𝐛\\mathbf{b}, 𝛌\\pmb \\lambda are similarly defined vectors.\nFrom here, the maximization of the expectation is now analogous to the maximization of generalized gamma distribution for each component of the mixture model.\nThe expectation of log-likelihood is 𝔼z|x[log(L(𝐱|𝐳))]=∑i=1n∑k=1Kziklogfk(xi)\\begin{equation}\n    \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]=\\sum^{n}_{i=1}\\sum^{K}_{k=1}z_{ik}\\log f_k(x_i) \\label{eq1}\n\\end{equation} and fk(x)=G(ak,bk,γk)=λkxakγk−1exp{(−x/bk)γk}bkakγkΓ(ak)\\begin{equation}\nf_k(x)=G(a_k,b_k,{\\gamma_k})=\\frac{\\lambda_k x^{a_k{\\gamma_k}-1}exp\\{(-x/b_k)^{{\\gamma_k}}\\}}{b_k^{a_k{\\gamma_k}}\\Gamma(a_k)} \\label{eq2}\n\\end{equation} where γk=1{\\gamma_k}=1.\nBy the two formulas above, The expected joint log-likelihood is\n𝔼z|x[log(L(𝐱|𝐳))]=∑k=1K∑i=1nzik(logγk−akγklogbk−logΓ(ak)+(akγk−1)logXi−(Xibk)γk)\\begin{multline} \\label{eq3}\n     \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]=\\sum^{K}_{k=1}\\sum^{n}_{i=1}z_{ik}\\left( \\log{\\gamma_k}-a_k{\\gamma_k} \\log b_k-log\\Gamma(a_k)+(a_k{\\gamma_k}-1)\\log X_i-(\\frac{X_i}{b_k})^{{\\gamma_k}} \\right)\n\\end{multline}\nThe estimators of each of the KK terms of the expected joint log-likelihood are derived as follows:\nfirst take derivative of the expression from the above equation ∑i=1nzik(logγk−akγklogbk−logΓ(ak)+(akγk−1)logXi−(Xibk)γk)\\begin{align*}\n    \\sum^{n}_{i=1} z_{ik}\\left( \\log{\\gamma_k}-a_k{\\gamma_k} \\log b_k-\\log\\Gamma(a_k)+(a_k{\\gamma_k}-1)\\log X_i-\\left(\\frac{X_i}{b_k}\\right)^{\\gamma_k} \\right)\n\\end{align*} with respect to ak,bk,γka_k, b_k, {\\gamma_k} separately:\n∂𝔼z|x[log(L(𝐱|𝐳))]∂ak=∑i=1nzik(−ψ(ak)−γklogbk+γkXi)=0(1)\\begin{align}\\label{eq4} \n      \\frac{\\partial \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]}{\\partial a_k}\n      =\\sum^{n}_{i=1} z_{ik}(-\\psi(a_k)-{\\gamma_k} \\log b_k+{\\gamma_k} X_i)=0 (1)\n  \\end{align} Note that ψ(x)=ddxlogΓ(x)\\psi(x)=\\displaystyle\\frac{d }{dx}\\log\\Gamma(x) is digamma function. ∂𝔼z|x[log(L(𝐱|𝐳))]∂bk=∑i=1n(zik)(−akγk/bk+γkXiγkbk−γk−1)=0(2)\\begin{align}\\label{eq5} \n    \\frac{\\partial \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]}{\\partial b_k}\n    =\\sum^{n}_{i=1}(z_{ik})(-a_k{\\gamma_k}/b_k+{\\gamma_k} X_i^{{\\gamma_k}} b_k^{-{\\gamma_k}-1})=0 (2)\n\\end{align} ∂𝔼z|x[log(L(𝐱|𝐳))]∂γk=∑i=1nzik(1γk−aklogbk+aklogXi−(Xibk)γklogXibk)=0(3)\\begin{align}\\label{eq6} \n    \\frac{\\partial \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]}{\\partial {\\gamma_k}}\n    =\\sum^{n}_{i=1}z_{ik}\\left(\\frac{1}{\\gamma_k}-a_k\\log b_k+a_k\\log X_i-\\left(\\frac{X_i}{b_k}\\right)^{\\gamma_k} \\log\\frac{X_i}{b_k}\\right)=0 (3)\n\\end{align} Among which, (2) can be solved as b̂k(ak,γk)=(∑i=1nzikXiγkak∑i=1nzik)1/γk(4)\\begin{equation} \\label{eq7}\n    \\hat b_k(a_k,{\\gamma_k})=\\left(\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i^{\\gamma_k}}{a_k\\displaystyle\\sum^{n}_{i=1}z_{ik}}\\right)^{1/{\\gamma_k}} (4)\n\\end{equation} Substitute (4) into (3): ∂𝔼z|x[log(L(𝐱|𝐳))]∂γk=∑i=1nzik/γk+∑i=1nakziklog(Xibk)−∑i=1nzik(Xibk)γklog(Xibk)=∑i=1nzik/γk+∑i=1nakzik(logXi−logbk)−bk−γk∑i=1nzikXiγk(logXi−logbk)=∑i=1nzik/γk+∑i=1nakziklogXi−logbk∑i=1nakzik−bk−γk∑i=1nzikXiγklogXi+bk−γklogbk∑i=1nzikXiγk=∑i=1nzik/γk+∑i=1nakziklogXi−logbk∑i=1nakzik−bk−γk∑i=1nzikXiγklogXiak∑i=1nzik∑i=1nzikXiγklogbk∑i=1nzikXiγk=∑i=1nzik/γk+∑i=1nakziklogXi−logbk∑i=1nakzik−bk−γk∑i=1nzikXiγklogXi+ak∑i=1nziklogbk=∑i=1nzik/γk+ak∑i=1nziklogXi−ak∑i=1nzik∑i=1nzikXiγk∑i=1nzikXiγklogXi=∑i=1nzik/γk+ak(∑i=1nziklogXi−∑i=1nzik∑i=1nzikXiγk∑i=1nzikXiγklogXi)=0\\begin{align*}\n    &\\frac{\\partial \\mathbb E_{z|x}[\\log(L(\\mathbf{x}|\\mathbf{z}))]}{\\partial {\\gamma_k}}\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+\\sum^{n}_{i=1}a_kz_{ik}\\log(\\frac{X_i}{b_k})-\\sum^{n}_{i=1}z_{ik}(\\frac{X_i}{b_k}) ^{\\gamma_k} \\log(\\frac{X_i}{b_k})\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+\\sum^{n}_{i=1}a_kz_{ik}(\\log X_i-\\log b_k)-b_k^{-{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} (\\log X_i-\\log b_k)\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+\\sum^{n}_{i=1}a_kz_{ik}\\log X_i-\\log b_k\\sum^{n}_{i=1}a_kz_{ik}-b_k^{-{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i+b_k^{-{\\gamma_k}}\\log b_k\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k}\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+\\sum^{n}_{i=1}a_kz_{ik}\\log X_i-\\log b_k\\sum^{n}_{i=1}a_kz_{ik}-b_k^{-{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i\n    \\frac {a_k\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i^{\\gamma_k}} \\log b_k\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k}\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+\\sum^{n}_{i=1}a_kz_{ik}\\log X_i-\\log b_k\\sum^{n}_{i=1}a_kz_{ik}-b_k^{-{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i+{a_k\\sum^{n}_{i=1}z_{ik}}\\log b_k\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+a_k\\sum^{n}_{i=1}z_{ik}\\log X_i-\\frac {a_k\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i^{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i\\\\\n    &=\\sum^{n}_{i=1}z_{ik}/{\\gamma_k}+a_k\\left(\\sum^{n}_{i=1}z_{ik}\\log X_i-\\frac {\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i^{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i\\right)=0\\\\\n\\end{align*}\nSolving this, we have âk(γk)=∑i=1nzikγk∑i=1nzik∑i=1nzikXiγk∑i=1nzikXiγklogXi−∑i=1nziklogXi(5)\\begin{equation} \\label{eq8}\n      \\hat a_k ({\\gamma_k})=\\displaystyle\\frac{\\displaystyle\\sum^{n}_{i=1}\\displaystyle\\frac{z_{ik}}{{\\gamma_k}}}\n      {\\displaystyle\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i^{\\gamma_k}}\\sum^{n}_{i=1}z_{ik}X_i ^{\\gamma_k} \\log X_i-\\sum^{n}_{i=1}z_{ik}\\log X_i} (5)\n  \\end{equation}\nPlug γk=1{\\gamma_k}=1 in (5) , we now have âk(γk=1)=∑i=1nzik∑i=1nzik∑i=1nzikXi∑i=1nzikXilogXi−∑i=1nziklogXi=(∑i=1nzikXilogXi∑i=1nzikXi−∑i=1nziklogXi∑i=1nzik)−1=∑i=1nzik∑i=1nzikXi∑i=1nzik∑i=1nzikXilogXi−∑i=1nziklogXi∑i=1nzikXi\\begin{align}\n  \\hat a_k ({\\gamma_k}=1)&=\\displaystyle\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\frac {\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}\\sum^{n}_{i=1}z_{ik}X_i  \\log X_i-\\sum^{n}_{i=1}z_{ik}\\log X_i}\\nonumber\\\\\n  &=\\left(\\frac {\\sum^{n}_{i=1}z_{ik}X_i\\log X_i}{\\sum^{n}_{i=1}z_{ik}X_i}-\\frac{\\sum^{n}_{i=1}z_{ik}\\log X_i}{\\sum^{n}_{i=1}z_{ik}}\\right)^{-1}\\nonumber\\\\\n  &=\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}{\\displaystyle\\sum^{n}_{i=1}z_{ik}\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i\\log X_i-\\displaystyle\\sum^{n}_{i=1}z_{ik}\\log X_i\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}\\label{eq:ak}\n  \\end{align} b̂k(âk,γk=1)=∑i=1nzikXiâk∑i=1nzik=∑i=1nzik∑i=1nzikXilogXi−∑i=1nziklogXi∑i=1nzikXi(∑i=1nzik)2\\begin{align}\n        \\hat b_k(\\hat a_k,{\\gamma_k}=1)&=\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}{\\hat a_k\\displaystyle\\sum^{n}_{i=1}z_{ik}} \\nonumber\\\\\n        %&=\\displaystyle\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}{\\displaystyle\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i\\displaystyle\\sum^{n}_{i=1}z_{ik}}{\\displaystyle\\sum^{n}_{i=1}z_{ik}\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i\\log X_i-\\displaystyle\\sum^{n}_{i=1}z_{ik}\\log X_i\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}\\displaystyle\\sum^{n}_{i=1}z_{ik}} \\nonumber\\\\\n        &=\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i\\log X_i-\\displaystyle\\sum^{n}_{i=1}z_{ik}\\log X_i\\displaystyle\\sum^{n}_{i=1}z_{ik}X_i}{\\left(\\displaystyle\\sum^{n}_{i=1}z_{ik}\\right)^2} \\label{eq:bk}\n  \\end{align} In addition, λ̂k\\hat {\\lambda}_k can simply be estimated as λ̂k=∑i=1nzikn\\begin{equation}\n    \\hat {\\lambda}_k =\\frac{\\displaystyle\\sum^{n}_{i=1}z_{ik}}{n} \\label{eq:lambdak}\n \\end{equation}\nIt is worth noting that we are not maximizing the exact Gamma distribution, therefore the algorithm we devise here is an EM-type algorithm."
  },
  {
    "objectID": "GammaGateR.html#results",
    "href": "GammaGateR.html#results",
    "title": "2  Chapter 2: GammaGateR",
    "section": "2.4 Results",
    "text": "2.4 Results\n\n2.4.1 Simulation for cfGMM\nTo compare the bias and compute time of the closed-form GMM to maximum likelihood GMM implementation, we run the cfGMM, the constrained cfGMM, and the GMM to evaluate bias and variance in a sample size of 10,000 across 1,000 simulations. We simulate a two-component mixture model with parameters 𝛌=(0.3,0.7),𝐚=(0.5,8),𝐛=(0.5,1/3)\\pmb{\\lambda} = (0.3, 0.7), \\pmb{a} = (0.5, 8), \\pmb{b} = (0.5, 1/3). For the constrained estimator, we restrict the mode of each component to be in the range (−∞,0)(-\\infty, 0) and (0,5)(0,5) for marker negative and marker positive components, respectively, which include the true mode for each component, 00 (no mode) and 7/37/3.\nBoth closed-form estimation procedures have substantially faster computation time than the MLE while maintaining similarly low bias, as in Figure 2.2. The sample size used in the simulation is roughly similar to that of the cell-level mIF image dataset, which further proves that cfGMM brings computation efficiency to our target application. The closed-form GMM, therefore, enables computationally feasible, precise, and flexible model estimation when applied to a large number of channels and slides using GammaGateR. It is also worth noting that the constrained cfGMM converges slightly faster than without constraints. This implies that when using cfGMM, computational cost can be reduced with proper knowledge of biological priors.\n\n\n\n\n\n\nFigure 2.2: Simulation results for cfGMM performance evaluation. a) Run time comparison (in minutes) for three methods: GMM, cfGMM and cfGMM with constraints. b) Estimated bias across 1,000 simulations in a sample size of 10,000.\n\n\n\n\n\n\n\nFigure 2.3: Performance evaluation for GammaGateR on the three datasets. “Posterior” and “marginal” refer to the posterior and marginal probabilities from GammaGateR, respectively. Cell phenotyping performance comparing GammaGateR to ASTIR in the (a) Colon MAP and (b) CRC Spatial atlas. (c) Survival prediction performance error in the ovarian cancer dataset, measured by 1-C-index. “Base” indicates the survival model including only age and cancer stage variables.\n\n\n\n\n\n\n\n2.4.2 Analysis in real dataset\nWe use three single-cell imaging datasets to evaluate model performance and demonstrate the use of the GammaGateR analysis pipeline: the Colorectal Molecular Atlas Project (Colon MAP) dataset (Chen et al. 2021), the Spatial Colorectal Cancer (CRC) Atlas dataset (Heiser et al. 2023) and Ovarian Cancer dataset (Steinhart et al. 2021; Wrobel and Ghosh 2022). After processing and prior to analysis, cell expression values were normalized by first mean division then log10 transformation to reduce slide-to-slide variation (Harris et al. 2022).\nTo compare the methods in determining cell phenotypes we assess the accuracy of each method relative to a “silver standard” manual phenotyping in the Colon MAP and CRC atlas datasets and evaluate the efficacy in predicting survival in the ovarian cancer data. We compare phenotyping results obtained using GammaGateR and ASTIR to “silver standard” manual phenotyping using the Adjusted Rand Index (Hubert and Arabie 1985). Adjusted rand index typically takes values between 0 and 1, where a larger value indicates a better alignment between two categorical variables. The silver standard is obtained by gating the raw images based on visual inspection and defining marker-positive cells as those that contain more than 50% marker-positive pixels within each cell. Semi-automated marker gating results are obtained using GammaGateR as described in Section 2.3.1, with monotonically adjusted posterior probability and marginal probability thresholded at 0.5 to define marker positive cells. The same phenotype definitions used for ASTIR are used to define phenotypes from marker positive labels using GammaGateR and manual marker gating as well. Each cell belongs to a given phenotype if it is marker positive for combinations of markers for that phenotype. ASTIR phenotypes are determined by selecting the cell type with the maximum probability for each cell. All methods use the same combinations of markers to define phenotypes. For both datasets and all cell types in these datasets, the posterior probability by GammaGateR yields higher Median ARI (Figure 2.3 a & b). This means that the posterior probability has consistently greater similarity to the silver standard than marginal probability and ASTIR (Figure 2.3 a & b). However, for some cell types (e.g. Macrophage, B-cells, Myeloid), all methods have low performance. This is an indication of systematic difference in how the algorithms identify positive cells relative to the manual labels.\nBecause the Ovarian Cancer dataset does not include manual cell phenotypes, we instead compare the prediction accuracy of survival time data for each method across all patients in the study to determine if one method has greater biological sensitivity than the other. The original study shows that survival of ovarian cancer patients is significantly correlated with B-cell and CD4 T-cell, as well as spatial interaction between CD4 T-cell and macrophage. Therefore, we evaluate the methods using this dataset by fitting a survival model with age, cancer stage, B-cell proportions, CD4 T-cell proportions, and the spatial interaction between Macrophage and CD4 T-cells estimated by Ripley’s H with r=50 (Kiskowski, Hancock, and Kenworthy 2009). Ripley’s H is a geospatial index that describes spatial attraction/repulsion. We fit a model for each method, where the cell phenotypes are determined using the given method, and compare all models, as well as a base model that includes only age and cancer stage. We use a random forest survival model to be sensitive to complex nonlinear relationships (Ishwaran et al. 2008; Ishwaran, Kogalur, and Kogalur 2023). To estimate variability in the out-of-bag performance error, we compare the methods across 100 bootstrap samples. Performance error quantification is based on C-index (Harrell et al. 1982), where a low performance error means that the model is a good fit, and a performance error of 0.5 is a random chance. For all methods, incorporating the cell-level information reduces out-of-bag error performance by approximately 0.075, over the base model that includes only age and cancer stage. This indicates that spatial cell phenotype covariates are useful in predicting survival outcomes, consistent with the original findings in Steinhart et al. (2021). The posterior probability slightly outperforms other methods, having the lowest prediction error in 46% of the bootstrap samples, compared to 36% with ASTIR and 18% with the marginal probability (Figure 2.3 c)."
  },
  {
    "objectID": "GammaGateR.html#summary",
    "href": "GammaGateR.html#summary",
    "title": "2  Chapter 2: GammaGateR",
    "section": "2.5 Summary",
    "text": "2.5 Summary\nGammaGateR is a semi-automated maker gating tool. Driven by a novel cfGMM estimation framework, GammaGateR generates reproducible and evaluable marker gating for mIF data. In addition, cfGMM enables computationally feasible model estimation for large-scale datasets like mIF. The marker gating output of GammaGateR can be used to define phenotypes and as input to downstream analysis. GammaGateR implements interactive visualization to quality check the clustering results (see vignette in Supplementary Material) and allows users to modify the constraints to improve model results when needed. Consequently, GammaGateR provides more consistent results with silver standard labels than ASTIR, the existing state-of-the-art method for automated phenotyping of cell-level mIF data. In the examples shown in this section, GammaGateR phenotypes had slightly improved ovarian cancer survival prediction accuracy compared to ASTIR. This paper also compares the posterior and the marginal probabilities returned by GammaGateR. The marginal probabilities only use the marker positive cell distribution to determine cell phenotypes, whereas the posterior probabilities take into account the distribution of the marker negative cells. Using posterior probabilities was almost always better indicating the importance of accounting for the full distribution of the marker intensities when identifying marker-positive cells.\n\n\n\n\nAhmadian, Mansooreh, Christian Rickert, Angela Minic, Julia Wrobel, Benjamin G Bitler, Fuyong Zing, Michael Angelo, Elena W Hsieh, Debashis Ghosh, and Kimberly R Jordan. 2022. “A Platform-Independent Framework for Phenotyping of Multiplex Tissue Imaging Data.” bioRxiv, 2022–10.\n\n\nAmitay, Yael, Yuval Bussi, Ben Feinstein, Shai Bagon, Idan Milo, and Leeat Keren. 2023. “CellSighter: A Neural Network to Classify Cells in Highly Multiplexed Images.” Nature Communications 14 (1): 4302.\n\n\nChen, Bob, Scurrah Cherie’R, Eliot T McKinley, Alan J Simmons, Marisol A Ramirez-Solano, Xiangzhu Zhu, Nicholas O Markham, et al. 2021. “Differential Pre-Malignant Programs and Microenvironment Chart Distinct Paths to Malignancy in Human Colorectal Polyps.” Cell 184 (26): 6262–80.\n\n\nGeuenich, Michael J, Jinyu Hou, Sunyun Lee, Shanza Ayub, Hartland W Jackson, and Kieran R Campbell. 2021. “Automated Assignment of Cell Identity from Single-Cell Multiplexed Imaging and Proteomic Data.” Cell Systems 12 (12): 1173–86.\n\n\nGraf, John, Sanghee Cho, Elizabeth McDonough, Alex Corwin, Anup Sood, Andreas Lindner, Manuela Salvucci, et al. 2022. “FLINO: A New Method for Immunofluorescence Bioimage Normalization.” Bioinformatics 38 (2): 520–26.\n\n\nHarrell, Frank E, Robert M Califf, David B Pryor, Kerry L Lee, and Robert A Rosati. 1982. “Evaluating the Yield of Medical Tests.” Jama 247 (18): 2543–46.\n\n\nHarris, Coleman R, Eliot T McKinley, Joseph T Roland, Qi Liu, Martha J Shrubsole, Ken S Lau, Robert J Coffey, Julia Wrobel, and Simon N Vandekar. 2022. “Quantifying and Correcting Slide-to-Slide Variation in Multiplexed Immunofluorescence Images.” Bioinformatics 38 (6): 1700–1707.\n\n\nHeiser, Cody N, Alan J Simmons, Frank Revetta, Eliot T McKinley, Marisol A Ramirez-Solano, Jiawei Wang, Justin Shao, et al. 2023. “Molecular Cartography Uncovers Evolutionary and Microenvironmental Dynamics in Sporadic Colorectal Tumors.” bioRxiv, 2023–03.\n\n\nHubert, Lawrence, and Phipps Arabie. 1985. “Comparing Partitions.” Journal of Classification 2: 193–218.\n\n\nHunt, Gregory J, Mark A Dane, James E Korkola, Laura M Heiser, and Johann A Gagnon-Bartsch. 2022. “Systematic Replication Enables Normalization of High-Throughput Imaging Assays.” Bioinformatics 38 (21): 4934–40.\n\n\nIshwaran, Hemant, Udaya B Kogalur, Eugene H Blackstone, and Michael S Lauer. 2008. “Random Survival Forests.”\n\n\nIshwaran, Hemant, Udaya B Kogalur, and Maintainer Udaya B Kogalur. 2023. “Package ‘randomForestSRC’.” Breast 6 (1): 854.\n\n\nKiskowski, Maria A, John F Hancock, and Anne K Kenworthy. 2009. “On the Use of Ripley’s k-Function and Its Derivatives to Analyze Domain Size.” Biophysical Journal 97 (4): 1095–1103.\n\n\nLin, Jia-Ren, Shu Wang, Shannon Coy, Yu-An Chen, Clarence Yapp, Madison Tyler, Maulik K Nariya, et al. 2023. “Multiplexed 3D Atlas of State Transitions and Immune Interaction in Colorectal Cancer.” Cell 186 (2): 363–81.\n\n\nMcLachlan, Geoffrey J, Sharon X Lee, and Suren I Rathnayake. 2019. “Finite Mixture Models.” Annual Review of Statistics and Its Application 6: 355–78.\n\n\nSteinhart, Benjamin, Kimberly R Jordan, Jaidev Bapat, Miriam D Post, Lindsay W Brubaker, Benjamin G Bitler, and Julia Wrobel. 2021. “The Spatial Context of Tumor-Infiltrating Immune Cells Associates with Improved Ovarian Cancer Survival.” Molecular Cancer Research 19 (12): 1973–79.\n\n\nWilson, Christopher M, Oscar E Ospina, Mary K Townsend, Jonathan Nguyen, Carlos Moran Segura, Joellen M Schildkraut, Shelley S Tworoger, Lauren C Peres, and Brooke L Fridley. 2021. “Challenges and Opportunities in the Statistical Analysis of Multiplex Immunofluorescence Data.” Cancers 13 (12): 3031.\n\n\nWrobel, J, and T Ghosh. 2022. “VectraPolarisData: Vectra Polaris and Vectra 3 Multiplex Single-Cell Imaging Data.” Bioconductor R Package Version 1.\n\n\nYe, Zhi-Sheng, and Nan Chen. 2017. “Closed-Form Estimators for the Gamma Distribution Derived from Likelihood Equations.” The American Statistician 71 (2): 177–81."
  },
  {
    "objectID": "Missing Data Imputation in mIF.html#application-case-1-missing-tissue-imputation",
    "href": "Missing Data Imputation in mIF.html#application-case-1-missing-tissue-imputation",
    "title": "3  Chapter 3: Missing data imputation in mIF imaging",
    "section": "3.1 Application case 1: Missing tissue imputation",
    "text": "3.1 Application case 1: Missing tissue imputation\n\n3.1.1 Method: GANs\nThe fundamental version of GANs comprises of two compartments: a discriminator and a generator (Goodfellow et al. 2014). Figure 3.2 by Bok and Langr (2019) gives a brief sketch of how GANs works. Like a turn-based strategy game, the two components take turns to run an epoch. Starting with a noise distribution (usually a uniform distribution), the generator’s goal is to generate data that is close to the real data. The discriminator’s goal is to identify the real data between a mix of real data and data generated by the generator. With classification error fed back to generator and discriminator, both opponents update their weights: the generator will try to maximize the probability that the discriminator misclassify generated data as real, and the discriminator will try to maximize classification accuracy. Within infinite number of rounds, they will eventually reach a state close to equilibrium, where either party can only improve negligibly: generator generates close-to-real data, and discriminator classifies with 50% accuracy(Bok and Langr 2019). This is the point where the algorithm stops.\n\n\n\nFigure 3.2: Illustration of how GANs work. 2. represents noise data input, and x*x^* is the “fake” data generated by 3. generator. The goal of the generator is to produce data very similar to real data. 1. represents real data (some hand written digits. Real data xx is sent to 4. discriminator along with x*x^*. The discriminator then try to distinguish true data from generated data. Finally, 5. the classification error is sent back to both 3 and 4 to iteratively train for better performance. Image courtesy of Bok and Langr (2019)\n\n\nThe value function of GANs can be written as formula as follows. D(x)D(x) represents the probability that discriminator classify xx as real data. zz is the noise distribution. G(z)G(z) is the fake data that generator creates based on the noise distribution.\nminGmaxDV(D,G)=Ex∼pdata(x)[logD(x)]+Ez∼pz(z)[log(1−D(G(z)))]\n\\min_G \\max_D V(D,G) = E_{x\\sim p_{data}(x)}[\\log D(x)] + E_{z\\sim p_{z}(z)}[\\log (1-D(G(z)))]\n Discriminator is trained to maximize V(D,G)V(D,G), and the generator is trained to minimize Ez∼pz(z)[log(1−D(G(z)))]E_{z\\sim p_{z}(z)}[\\log (1-D(G(z)))], the probability that fake data is recognized and classified as fake data.\nOne disadvantage of the original GANs is its weak control on the generated data, due to the random noise input. This disadvantage stands out especially with image synthesis. Conditional GANs (CGANs) provided a promising solution to this issue by including auxiliary information on both generator and discriminator (Mirza and Osindero 2014). The auxiliary information is usually data from the same class, for example other images in the case of image synthesis. Suppose xx belongs to the input data class, and yy is the intended output data class. GANs would learn the mapping of G:z→yG: z \\rightarrow y, while CGANs learns G:x,z→yG: {x,z} \\rightarrow y (Isola et al. 2017; Souza et al. 2023). The updated value function for CGANs is as follows:\nminGmaxDV(D,G)=Ex,y[logD(x)]+Ex,z[log(1−D(x,G(x,z)))](3.1)\n\\min_G \\max_D V(D,G) = E_{x,y}[\\log D(x)] + E_{x,z}[\\log (1-D(x, G(x,z)))]\n \\qquad(3.1)\nBased on this, pix2pix is developed. It is able to perform image-to-image translation by using image pairs (x,y)(x,y) to train the data. Figure 3.3 shows the types of (x,y)(x,y) it use. Intuitively, image imputation can utilize this idea: with sets of channels that does not have missing data, well-trained pix2pix can generate imputed data.\n\n\n\nFigure 3.3: Input and output image pair example for pix2pix. Image courtesy of Isola et al. (2017).\n\n\n\n\n3.1.2 Application in mIF: pixN2N-HD\npixN2N-HD is a “novel multi-channel high-resolution image synthesis approach”, an extension based on pix2pix. “N2N” represents “N-to-N”, which distinguishes itself from the widely-used (N-1)-to-1 model. N represents the number of marker channels, and in the dataset used in this paper, N=11. In (N-1)-to-1 design, 10 channels are used as input and 1 channel is used as output, and this repeats for 11 permutations of models. The “N-to-N” instead uses a random gate strategy, as shown in Figure 3.4. Let δ\\delta be the binary vector indicating channels without missing tissue. When δ(i)\\delta^{(i)} is turned on, image of the ithith channel will go into the generator; when turned off, a blank image will be feed into the generator instead. The value function is similar to Equation 3.1. X=δ(M)X=\\delta(M), the non-missing channels is the input, and Y=δ‾(M)Y=\\bar\\delta(M) is the output.\nminGmaxDV(D,G)=EX,Y[logD(X)]+EX[log(1−D(X,G(X)))]\n\\min_G \\max_D V(D,G) = E_{X,Y}[\\log D(X)] + E_{X}[\\log (1-D(X, G(X)))]\n\n\n\n\nFigure 3.4: Work flow of pixN2N-HD. The topleft binary vector is the random gate, where 1 represents channels with missing tissue and 0 represents channels without missing tissue. Images from intact marker channels are sent to the both generator and discriminator as auxiliary information. Generator synthesizes images of all marker channels, and only the image for marker channel that has missing tissues are sent to discriminator. The discriminator then try to classify real and imputed image for the missing channel. Image courtesy of Bao et al. (2021).\n\n\nThis paper evaluated the model performance by comparing “N-to-N” model with “(N-1)-to-1” model and another “(N-1)-to-1 random gate” model, which blends in random gate but still needs to train 11 separate models. An index for measuring image similarity, the structure similarity index measure (SSIM) is used to assess whether “N-to-N” model generates comparable results with the other two methods (Wang et al. 2004). The result shows that all pairs of methods do not have significantly different results on a 0.05 significance level, and therefore the methods are concluded to be comparable. This “N-to-N” model take significantly less amount of time to train compared to the other methods, which is very meaningful in terms of effective computation."
  },
  {
    "objectID": "Missing Data Imputation in mIF.html#application-case-2-marker-channel-imputation",
    "href": "Missing Data Imputation in mIF.html#application-case-2-marker-channel-imputation",
    "title": "3  Chapter 3: Missing data imputation in mIF imaging",
    "section": "3.2 Application case 2: Marker channel imputation",
    "text": "3.2 Application case 2: Marker channel imputation\nBoth 7-UP and CyCIF panel reduction are intended for marker channel imputation, providing access to otherwise expensive high-plex (40+ channels) mIF image for study that can only obtain low-plex images. Interestingly, the two application uses very different methods for imputation.\n\n3.2.1 Application 2.1: 7-UP\n7-UP starts from a 7-plex mIF image and generates high-plex image that can identify up to 16 different cell types (Wu et al. 2023). This approach consists of three main parts:\n\nMarker panel selection. This part will select the seven markers to start with, using concrete autoencoder. Concrete autoencoder is an feature selection method, of which the loss function is the difference between the original sample and the reconstructed low-dimension sample (Balın, Abid, and Zou 2019).\nMorphology feature extraction. This step uses a convolutional neural network to learn the morphology features, i.e. spatial and structural features of cells. Convolutional neural networks are similar to layers of linear regressions, where there are more combinations of weights linked to each input variable.\nMarker expression imputation. Once the location and structure of cells are learned, the important task left is to impute the expression of each marker on each cell. The imputation is performed using XGBoost, a scalable gradient-boosting tree software (Chen and Guestrin 2016).\n\nA series of evaluation and analysis are performed to show the validity of the method. The performance of the method is examined in three ways:\n\nCalculating the pearson correlation coefficient between the imputed marker expression and the testing data marker expression.\nCalculating the F1 score between the imputed and testing data cell type. F1-score is the harmonic mean of precision and sensitivity: 2/(sensitivity−1+precision−1)2/(sensitivity^{-1}+precision^{-1}). Cell type is generated from the marker expression through k-nearest neighbor.\nPatient survival status, HPV status and disease recurrence are used to further evaluate the cell type outcomes. AUC score for patient status prediction is calculated for both imputed data outcome and training data.\n\nAll evluation shows that the imputation generates comparable results with the training data, hence proven the validity of this method.\n\n\n3.2.2 Application 2.2: CyCIF panel reduction\nThis method is intended to be an improvement from their own previous work (Ternes et al. 2022). The previous work first go through panel selection and then imputes marker channel with variatioal autoencoder. The current improved method (Sims and Chang 2023) uses masked autoencoder for image synthesis as shown is Figure 3.5. The difference is the adoption of within-model iterative selection of marker panels, as the authors believe that panel selection should be more closely tied with panel reconstruction. Starting with standard DAPI, each marker is added to the panel, predict marker intensities of other panels, and mean Spearman correlation is calculated between the predicted intensity and real intensity. The marker with highest correlation is selected, and the next round continues until the panel is constructed. The ratio of masked channels depends on tasks, though 25%~75% is a reasonable range.\nThe method outcome is evaluated by Spearman correlation with the true data. It is shown in the results that both MAE and the iterative panel selection outperforms the VAE and out-of-box panel selection of the previous method.\n\n\n\nFigure 3.5: CyCIF panel reduction with autoencoder. The left hand side is the masked marker panel, where the mask represents missing marker channels. Next, in the encoder step, the masked markers are translated to a lower-dimnesion latent space. The masked panels are then “imputed” through the decoder step, where latent space information are tranlated back to the same dimension space as the imput image, creating full panel of desired markers. Figure courtesy of Sims and Chang (2023).\n\n\n\n\n\n\nBalın, Muhammed Fatih, Abubakar Abid, and James Zou. 2019. “Concrete Autoencoders: Differentiable Feature Selection and Reconstruction.” In International Conference on Machine Learning, 444–53. PMLR.\n\n\nBao, Shunxing, Yucheng Tang, Ho Hin Lee, Riqiang Gao, Sophie Chiron, Ilwoo Lyu, Lori A Coburn, et al. 2021. “Random Multi-Channel Image Synthesis for Multiplexed Immunofluorescence Imaging.” In MICCAI Workshop on Computational Pathology, 36–46. PMLR.\n\n\nBok, Vladimir, and Jakub Langr. 2019. GANs in Action: Deep Learning with Generative Adversarial Networks. Simon; Schuster.\n\n\nChen, Tianqi, and Carlos Guestrin. 2016. “Xgboost: A Scalable Tree Boosting System.” In Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, 785–94.\n\n\nGoodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” Advances in Neural Information Processing Systems 27.\n\n\nIsola, Phillip, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. 2017. “Image-to-Image Translation with Conditional Adversarial Networks.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1125–34.\n\n\nMirza, Mehdi, and Simon Osindero. 2014. “Conditional Generative Adversarial Nets.” arXiv Preprint arXiv:1411.1784.\n\n\nSims, Zachary, and Young Hwan Chang. 2023. “A Masked Image Modeling Approach to Cyclic Immunofluorescence (CyCIF) Panel Reduction and Marker Imputation.” bioRxiv, 2023–05.\n\n\nSouza, Vinicius Luis Trevisan de, Bruno Augusto Dorta Marques, Harlen Costa Batagelo, and João Paulo Gois. 2023. “A Review on Generative Adversarial Networks for Image Generation.” Computers & Graphics.\n\n\nTernes, Luke, Jia-Ren Lin, Yu-An Chen, Joe W Gray, and Young Hwan Chang. 2022. “Computational Multiplex Panel Reduction to Maximize Information Retention in Breast Cancer Tissue Microarrays.” PLoS Computational Biology 18 (9): e1010505.\n\n\nWang, Zhou, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli. 2004. “Image Quality Assessment: From Error Visibility to Structural Similarity.” IEEE Transactions on Image Processing 13 (4): 600–612. https://doi.org/10.1109/TIP.2003.819861.\n\n\nWu, Eric, Alexandro E Trevino, Zhenqin Wu, Kyle Swanson, Honesty J Kim, H Blaize D’Angio, Ryan Preska, et al. 2023. “7-UP: Generating in Silico CODEX from a Small Set of Immunofluorescence Markers.” PNAS Nexus 2 (6): pgad171."
  },
  {
    "objectID": "summary.html#multiple-imputation",
    "href": "summary.html#multiple-imputation",
    "title": "4  Chapter 4: Future directions",
    "section": "4.1 Multiple imputation",
    "text": "4.1 Multiple imputation\nAll methods in Chapter 3 evaluated the accuracy of their result by either comparing with the imputation outcome of a previous method or with a held-out evaluation dataset. In addition, Wu et al. (2023) in Section 3.2.1 used the imputation output for cell phenotyping and predicting patient phenotypic outcomes. In principle, this is not the best practice of subsequent analysis with the imputation outcome. Point estimates from such imputation underestimates the standard deviation of the point estimates, as shown below.\nRubin (1996) states that it is important to be statistically valid for estimates of scientific estimands, such as population mean. Statistical validity for an estimand means an at least approximately non-biased point estimate, and an statistical test that rejects the null hypothesis no more than 5% of the time, when the nominal significance level is 5% (Rubin 1996; Van Buuren 2018). Under such guideline, we can check the multiple imputation estimand’s expectation and variance. Van Buuren (2018) presented a clear interpretation of such, conditioning on observed data: Let YmisY_{mis} be missing data, and YobsY_{obs} be observed data, QQ be the population value and Q̂\\hat Q is the estimate of QQ. The posterior distribution of QQ given observed data is\nP(Q|Yobs)=∫P(Q|Yobs,Ymis)P(Ymis|Yobs)dYmis\nP(Q|Y_{obs})=\\int P(Q|Y_{obs}, Y_{mis})P(Y_{mis}|Y_{obs})dY_{mis}\n\nThe posterior mean of QQ is therefore\nE[Q|Yobs]=E[E(Q|Yobs,Ymis)|Yobs]\nE[Q|Y_{obs}]=E[E(Q|Y_{obs}, Y_{mis})|Y_{obs}]\n\nWhich can be interpreted as the average of estimates over repeatedly imputed data, given the observed data.\nThe posterior variance is therefore\nVar(Q|Yobs)=E[Var(Q|Yobs,Ymis)|Yobs]+Var[E(Q|Yobs,Ymis)|Yobs]\nVar(Q|Y_{obs})=E[Var(Q|Y_{obs}, Y_{mis})|Y_{obs}]+Var[E(Q|Y_{obs}, Y_{mis})|Y_{obs}]\n Which can be interpreted as the within-variance of the estimate in each imputed data, and the between-variance among the repeatedly imputed data.\nIn this case, single imputation would be an unbiased estimator. However, it will be biased in variance estimation, as it does not incorporate between-variance at all (the second proportion of the last equation RHS). Therefore, for better accuracy with estimate variance, multiple imputation should be used. The subsequent project could use the colon map data in GammaGateR project, where some channels are missing, and compare the validity of confidence interval for the estimated quantities."
  },
  {
    "objectID": "summary.html#imputation-with-patient-information",
    "href": "summary.html#imputation-with-patient-information",
    "title": "4  Chapter 4: Future directions",
    "section": "4.2 Imputation with patient information",
    "text": "4.2 Imputation with patient information\nAs described in Wu et al. (2023), cell phenotypes are usually considered with certain prognostic information, such as patient survival, recurrence, and disease status. That is, suppose we want to estimate a certain parameter θ\\theta, patient parameters XX, we are assuming\nθ=E[g(X,Yobs,Ymis)]\n\\theta=E[g(X, Y_{obs}, Y_{mis})]\n and hence Ymis=f(X,Yobs)+ϵ,ϵ⊥(X,Yobs)\nY_{mis}=f(X, Y_{obs})+\\epsilon, \\epsilon \\perp (X, Y_{obs})\n\nThe existing imputation methods all uses Ymis=f(Yobs)+ϵY_{mis}=f(Y_{obs})+\\epsilon. That is, there exists bias of f(X,Yobs)−f(Yobs)\nf(X, Y_{obs})-f(Y_{obs})\n\nThis bias can only be ignored if we assume that Ymis⊥X|YobsY_{mis} \\perp X|Y_{obs}. That is, patient information does not contribute to the prediction of missing data given observed data. This is a bold assumption to make, and should be avoided unless with concrete supporting prior knowledge.\n\n\n\n\nRubin, Donald B. 1996. “Multiple Imputation After 18+ Years.” Journal of the American Statistical Association 91 (434): 473–89.\n\n\nVan Buuren, Stef. 2018. Flexible Imputation of Missing Data. CRC press.\n\n\nWu, Eric, Alexandro E Trevino, Zhenqin Wu, Kyle Swanson, Honesty J Kim, H Blaize D’Angio, Ryan Preska, et al. 2023. “7-UP: Generating in Silico CODEX from a Small Set of Immunofluorescence Markers.” PNAS Nexus 2 (6): pgad171."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ahmadian, Mansooreh, Christian Rickert, Angela Minic, Julia Wrobel,\nBenjamin G Bitler, Fuyong Zing, Michael Angelo, Elena W Hsieh, Debashis\nGhosh, and Kimberly R Jordan. 2022. “A Platform-Independent\nFramework for Phenotyping of Multiplex Tissue Imaging Data.”\nbioRxiv, 2022–10.\n\n\nAmitay, Yael, Yuval Bussi, Ben Feinstein, Shai Bagon, Idan Milo, and\nLeeat Keren. 2023. “CellSighter: A Neural Network to Classify\nCells in Highly Multiplexed Images.” Nature\nCommunications 14 (1): 4302.\n\n\nBalın, Muhammed Fatih, Abubakar Abid, and James Zou. 2019.\n“Concrete Autoencoders: Differentiable Feature Selection and\nReconstruction.” In International Conference on Machine\nLearning, 444–53. PMLR.\n\n\nBao, Shunxing, Yucheng Tang, Ho Hin Lee, Riqiang Gao, Sophie Chiron,\nIlwoo Lyu, Lori A Coburn, et al. 2021. “Random Multi-Channel Image\nSynthesis for Multiplexed Immunofluorescence Imaging.” In\nMICCAI Workshop on Computational Pathology, 36–46. PMLR.\n\n\nBok, Vladimir, and Jakub Langr. 2019. GANs in Action: Deep Learning\nwith Generative Adversarial Networks. Simon; Schuster.\n\n\nChen, Bob, Scurrah Cherie’R, Eliot T McKinley, Alan J Simmons, Marisol A\nRamirez-Solano, Xiangzhu Zhu, Nicholas O Markham, et al. 2021.\n“Differential Pre-Malignant Programs and Microenvironment Chart\nDistinct Paths to Malignancy in Human Colorectal Polyps.”\nCell 184 (26): 6262–80.\n\n\nChen, Tianqi, and Carlos Guestrin. 2016. “Xgboost: A Scalable Tree\nBoosting System.” In Proceedings of the 22nd Acm Sigkdd\nInternational Conference on Knowledge Discovery and Data Mining,\n785–94.\n\n\nCoons, Albert H, Hugh J Creech, and R Norman Jones. 1941.\n“Immunological Properties of an Antibody Containing a Fluorescent\nGroup.” Proceedings of the Society for Experimental Biology\nand Medicine 47 (2): 200–202.\n\n\nDuraiyan, Jeyapradha, Rajeshwar Govindarajan, Karunakaran Kaliyappan,\nand Murugesan Palanisamy. 2012. “Applications of\nImmunohistochemistry.” Journal of Pharmacy & Bioallied\nSciences 4 (Suppl 2): S307.\n\n\nEng, Jennifer, Elmar Bucher, Zhi Hu, Ting Zheng, Summer L Gibbs, Koei\nChin, and Joe W Gray. 2022. “A Framework for Multiplex Imaging\nOptimization and Reproducible Analysis.” Communications\nBiology 5 (1): 438.\n\n\nGeuenich, Michael J, Jinyu Hou, Sunyun Lee, Shanza Ayub, Hartland W\nJackson, and Kieran R Campbell. 2021. “Automated Assignment of\nCell Identity from Single-Cell Multiplexed Imaging and Proteomic\nData.” Cell Systems 12 (12): 1173–86.\n\n\nGoodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David\nWarde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014.\n“Generative Adversarial Nets.” Advances in Neural\nInformation Processing Systems 27.\n\n\nGraf, John, Sanghee Cho, Elizabeth McDonough, Alex Corwin, Anup Sood,\nAndreas Lindner, Manuela Salvucci, et al. 2022. “FLINO: A New\nMethod for Immunofluorescence Bioimage Normalization.”\nBioinformatics 38 (2): 520–26.\n\n\nHarrell, Frank E, Robert M Califf, David B Pryor, Kerry L Lee, and\nRobert A Rosati. 1982. “Evaluating the Yield of Medical\nTests.” Jama 247 (18): 2543–46.\n\n\nHarris, Coleman R, Eliot T McKinley, Joseph T Roland, Qi Liu, Martha J\nShrubsole, Ken S Lau, Robert J Coffey, Julia Wrobel, and Simon N\nVandekar. 2022. “Quantifying and Correcting Slide-to-Slide\nVariation in Multiplexed Immunofluorescence Images.”\nBioinformatics 38 (6): 1700–1707.\n\n\nHeiser, Cody N, Alan J Simmons, Frank Revetta, Eliot T McKinley, Marisol\nA Ramirez-Solano, Jiawei Wang, Justin Shao, et al. 2023.\n“Molecular Cartography Uncovers Evolutionary and\nMicroenvironmental Dynamics in Sporadic Colorectal Tumors.”\nbioRxiv, 2023–03.\n\n\nHubert, Lawrence, and Phipps Arabie. 1985. “Comparing\nPartitions.” Journal of Classification 2: 193–218.\n\n\nHunt, Gregory J, Mark A Dane, James E Korkola, Laura M Heiser, and\nJohann A Gagnon-Bartsch. 2022. “Systematic Replication Enables\nNormalization of High-Throughput Imaging Assays.”\nBioinformatics 38 (21): 4934–40.\n\n\nHussaini, Haizal Mohd, Benedict Seo, and Alison M Rich. 2022.\n“Immunohistochemistry and Immunofluorescence.” In Oral\nBiology: Molecular Techniques and Applications, 439–50. Springer.\n\n\nIshwaran, Hemant, Udaya B Kogalur, Eugene H Blackstone, and Michael S\nLauer. 2008. “Random Survival Forests.”\n\n\nIshwaran, Hemant, Udaya B Kogalur, and Maintainer Udaya B Kogalur. 2023.\n“Package ‘randomForestSRC’.” Breast 6\n(1): 854.\n\n\nIsola, Phillip, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. 2017.\n“Image-to-Image Translation with Conditional Adversarial\nNetworks.” In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, 1125–34.\n\n\nKiskowski, Maria A, John F Hancock, and Anne K Kenworthy. 2009.\n“On the Use of Ripley’s k-Function and Its Derivatives to Analyze\nDomain Size.” Biophysical Journal 97 (4): 1095–1103.\n\n\nLin, Jia-Ren, Shu Wang, Shannon Coy, Yu-An Chen, Clarence Yapp, Madison\nTyler, Maulik K Nariya, et al. 2023. “Multiplexed 3D Atlas of\nState Transitions and Immune Interaction in Colorectal Cancer.”\nCell 186 (2): 363–81.\n\n\nMcKinley, Eliot T, Justin Shao, Samuel T Ellis, Cody N Heiser, Joseph T\nRoland, Mary C Macedonia, Paige N Vega, Susie Shin, Robert J Coffey, and\nKen S Lau. 2022. “MIRIAM: A Machine and Deep Learning Single-Cell\nSegmentation and Quantification Pipeline for Multi-Dimensional Tissue\nImages.” Cytometry Part A 101 (6): 521–28.\n\n\nMcLachlan, Geoffrey J, Sharon X Lee, and Suren I Rathnayake. 2019.\n“Finite Mixture Models.” Annual Review of Statistics\nand Its Application 6: 355–78.\n\n\nMirza, Mehdi, and Simon Osindero. 2014. “Conditional Generative\nAdversarial Nets.” arXiv Preprint arXiv:1411.1784.\n\n\nRamos-Vara, Jose A. 2005. “Technical Aspects of\nImmunohistochemistry.” Veterinary Pathology 42 (4):\n405–26.\n\n\nRubin, Donald B. 1996. “Multiple Imputation After 18+\nYears.” Journal of the American Statistical Association\n91 (434): 473–89.\n\n\nSchüffler, Peter J, Denis Schapiro, Charlotte Giesen, Hao AO Wang, Bernd\nBodenmiller, and Joachim M Buhmann. 2015. “Automatic Single Cell\nSegmentation on Highly Multiplexed Tissue Images.” Cytometry\nPart A 87 (10): 936–42.\n\n\nSchürch, Christian M, Salil S Bhate, Graham L Barlow, Darci J Phillips,\nLuca Noti, Inti Zlobec, Pauline Chu, et al. 2020. “Coordinated\nCellular Neighborhoods Orchestrate Antitumoral Immunity at the\nColorectal Cancer Invasive Front.” Cell 182 (5):\n1341–59.\n\n\nSheng, Wenjie, Chaoyu Zhang, TM Mohiuddin, Marwah Al-Rawe, Felix\nZeppernick, Franco H Falcone, Ivo Meinhold-Heerlein, and Ahmad Fawzi\nHussain. 2023. “Multiplex Immunofluorescence: A Powerful Tool in\nCancer Immunotherapy.” International Journal of Molecular\nSciences 24 (4): 3086.\n\n\nSims, Zachary, and Young Hwan Chang. 2023. “A Masked Image\nModeling Approach to Cyclic Immunofluorescence (CyCIF) Panel Reduction\nand Marker Imputation.” bioRxiv, 2023–05.\n\n\nSouza, Vinicius Luis Trevisan de, Bruno Augusto Dorta Marques, Harlen\nCosta Batagelo, and João Paulo Gois. 2023. “A Review on Generative\nAdversarial Networks for Image Generation.” Computers &\nGraphics.\n\n\nSteinhart, Benjamin, Kimberly R Jordan, Jaidev Bapat, Miriam D Post,\nLindsay W Brubaker, Benjamin G Bitler, and Julia Wrobel. 2021.\n“The Spatial Context of Tumor-Infiltrating Immune Cells Associates\nwith Improved Ovarian Cancer Survival.” Molecular Cancer\nResearch 19 (12): 1973–79.\n\n\nTernes, Luke, Jia-Ren Lin, Yu-An Chen, Joe W Gray, and Young Hwan Chang.\n2022. “Computational Multiplex Panel Reduction to Maximize\nInformation Retention in Breast Cancer Tissue Microarrays.”\nPLoS Computational Biology 18 (9): e1010505.\n\n\nVan Buuren, Stef. 2018. Flexible Imputation of Missing Data.\nCRC press.\n\n\nWang, Zhou, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli. 2004.\n“Image Quality Assessment: From Error Visibility to Structural\nSimilarity.” IEEE Transactions on Image Processing 13\n(4): 600–612. https://doi.org/10.1109/TIP.2003.819861.\n\n\nWilson, Christopher M, Oscar E Ospina, Mary K Townsend, Jonathan Nguyen,\nCarlos Moran Segura, Joellen M Schildkraut, Shelley S Tworoger, Lauren C\nPeres, and Brooke L Fridley. 2021. “Challenges and Opportunities\nin the Statistical Analysis of Multiplex Immunofluorescence\nData.” Cancers 13 (12): 3031.\n\n\nWrobel, J, and T Ghosh. 2022. “VectraPolarisData: Vectra Polaris\nand Vectra 3 Multiplex Single-Cell Imaging Data.”\nBioconductor R Package Version 1.\n\n\nWrobel, Julia, Coleman Harris, and Simon Vandekar. 2023.\n“Statistical Analysis of Multiplex Immunofluorescence and\nImmunohistochemistry Imaging Data.” In Statistical\nGenomics, 141–68. Springer.\n\n\nWu, Eric, Alexandro E Trevino, Zhenqin Wu, Kyle Swanson, Honesty J Kim,\nH Blaize D’Angio, Ryan Preska, et al. 2023. “7-UP: Generating in\nSilico CODEX from a Small Set of Immunofluorescence Markers.”\nPNAS Nexus 2 (6): pgad171.\n\n\nYe, Zhi-Sheng, and Nan Chen. 2017. “Closed-Form Estimators for the\nGamma Distribution Derived from Likelihood Equations.” The\nAmerican Statistician 71 (2): 177–81."
  }
]